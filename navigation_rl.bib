@inproceedings{Pfeiffer2017,
abstract = {Learning from demonstration for motion planning is an ongoing research topic. In this paper we present a model that is able to learn the complex mapping from raw 2D-laser range findings and a target position to the required steering commands for the robot. To our best knowledge, this work presents the first approach that learns a target-oriented end-to-end navigation model for a robotic platform. The supervised model training is based on expert demonstrations generated in simulation with an existing motion planner. We demonstrate that the learned navigation model is directly transferable to previously unseen virtual and, more interestingly, real-world environments. It can safely navigate the robot through obstacle-cluttered environments to reach the provided targets. We present an extensive qualitative and quantitative evaluation of the neural network-based motion planner, and compare it to a grid-based global approach, both in simulation and in real-world experiments.},
author = {Pfeiffer, Mark and Schaeuble, Michael and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2017.7989182},
isbn = {9781509046331},
issn = {10504729},
title = {{From perception to decision: A data-driven approach to end-to-end motion planning for autonomous ground robots}},
year = {2017}
}
@inproceedings{Tai2017,
abstract = {We present a learning-based mapless motion planner by taking the sparse 10-dimensional range findings and the target position with respect to the mobile robot coordinate frame as input and the continuous steering commands as output. Traditional motion planners for mobile ground robots with a laser range sensor mostly depend on the obstacle map of the navigation environment where both the highly precise laser sensor and the obstacle map building work of the environment are indispensable. We show that, through an asynchronous deep reinforcement learning method, a mapless motion planner can be trained end-to-end without any manually designed features and prior demonstrations. The trained planner can be directly applied in unseen virtual and real environments. The experiments show that the proposed mapless motion planner can navigate the nonholonomic mobile robot to the desired targets without colliding with any obstacles.},
author = {Tai, Lei and Paolo, Giuseppe and Liu, Ming},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2017.8202134},
isbn = {9781538626825},
issn = {21530866},
title = {{Virtual-to-real deep reinforcement learning: Continuous control of mobile robots for mapless navigation}},
year = {2017}
}
